{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 1. Data Loading and Preprocessing\n",
    "# \n",
    "# This notebook loads the PBMC3k dataset, performs standard preprocessing,\n",
    "# and saves it for later use. We will also split it into a \"reference\"\n",
    "# and a \"query\" set for demonstration purposes.\n",
    "\n",
    "# %%\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path to import our package\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from scpred_py import _preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Load Data\n",
    "\n",
    "# %%\n",
    "adata = sc.datasets.pbmc3k()\n",
    "adata.var_names_make_unique()\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2610a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Preprocessing\n",
    "# \n",
    "# We apply standard filtering, normalization, log-transform, HVG selection, and scaling.\n",
    "# We'll use our custom preprocessing function to keep it consistent.\n",
    "\n",
    "# %%\n",
    "# Add some cell type annotations for training (using Scanpy's workflow)\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata_hvg = adata[:, adata.var.highly_variable].copy() # Work on HVG subset\n",
    "sc.pp.scale(adata_hvg, max_value=10)\n",
    "sc.tl.pca(adata_hvg, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata_hvg, n_neighbors=10, n_pcs=40)\n",
    "sc.tl.louvain(adata_hvg, random_state=42) # Use louvain clusters as 'cell types'\n",
    "\n",
    "# Map back the cell types to the full (but preprocessed) data\n",
    "adata.obs['cell_type'] = adata_hvg.obs['louvain']\n",
    "\n",
    "# Now apply our *intended* preprocessing (without PCA yet) for scPred\n",
    "adata_proc = _preprocessing.standard_preprocess(adata.copy())\n",
    "print(adata_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2982c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Split Data (Reference vs. Query)\n",
    "# \n",
    "# We'll randomly split the cells into 70% reference and 30% query.\n",
    "\n",
    "# %%\n",
    "n_cells = adata_proc.shape[0]\n",
    "indices = np.arange(n_cells)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "ref_idx = indices[:int(0.7 * n_cells)]\n",
    "query_idx = indices[int(0.7 * n_cells):]\n",
    "\n",
    "ref_adata = adata_proc[ref_idx, :].copy()\n",
    "query_adata = adata_proc[query_idx, :].copy()\n",
    "\n",
    "print(f\"Reference data shape: {ref_adata.shape}\")\n",
    "print(f\"Query data shape: {query_adata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Save Data\n",
    "# \n",
    "# We'll save these AnnData objects.\n",
    "\n",
    "# %%\n",
    "if not os.path.exists('../data/processed'):\n",
    "    os.makedirs('../data/processed')\n",
    "\n",
    "ref_adata.write('../data/processed/pbmc3k_ref.h5ad')\n",
    "query_adata.write('../data/processed/pbmc3k_query.h5ad')\n",
    "\n",
    "print(\"Data saved.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
